{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5dS6_TPPyv0"
      },
      "source": [
        "В коде я попытался реализовать архитектуру LeNet-5 для классификации изображений CIFAR10, описанную на данном сайте https://medium.com/@siddheshb008/lenet-5-architecture-explained-3b559cb2d52b. Точность на тестовой выборке – 0.5993."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZUgd4OiDh4EP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-31e0aCCUnss",
        "outputId": "d256829b-ac48-4152-8a84-a4850fb2738b"
      },
      "outputs": [],
      "source": [
        "# Downloading dataset from torchvision\n",
        "train_data = datasets.CIFAR10(root=\"./cifar10_data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "test_data = datasets.CIFAR10(root=\"./cifar10_data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Train and val split\n",
        "train_size = int(len(train_data) * 0.8)\n",
        "val_size = len(train_data) - train_size\n",
        "\n",
        "train_data, val_data = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
        "\n",
        "# Dataloaders to generate batches\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xJCM2lZYjtR"
      },
      "source": [
        "Definition of LeNet-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3UyozaPnUnsu"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolution layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5,5)) # 28x28\n",
        "        self.norm1 = nn.BatchNorm2d(6)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2)) # 14x14\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5)) # 10x10\n",
        "        self.norm2 = nn.BatchNorm2d(16)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2)) # 5x5\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5,5)) # 1x1\n",
        "        self.norm2 = nn.BatchNorm2d(120)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(1*1*120, 84)\n",
        "        self.fc2 = nn.Linear(84, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.tanh(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.tanh(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.tanh(self.conv3(x))\n",
        "        x = self.flatten(x)\n",
        "        x = F.tanh(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MFpILkiXhEz-"
      },
      "outputs": [],
      "source": [
        "model = ConvNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "keaqEK3ug9rd"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jYsRSxVjUntR"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, loss_fn):\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    num_correct = 0\n",
        "    num_elements = 0\n",
        "\n",
        "    for i, batch in enumerate(dataloader):\n",
        "\n",
        "        X_batch, y_batch = batch\n",
        "        num_elements += len(y_batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(X_batch.to(device))\n",
        "\n",
        "            loss = loss_fn(logits, y_batch.to(device))\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred = torch.argmax(logits, dim=1)\n",
        "\n",
        "            num_correct += torch.sum(y_pred.cpu() == y_batch)\n",
        "\n",
        "    accuracy = num_correct / num_elements\n",
        "\n",
        "    return accuracy.numpy(), np.mean(losses)\n",
        "\n",
        "def train(model, loss_fn, optimizer, n_epoch=3):\n",
        "\n",
        "    for epoch in range(n_epoch):\n",
        "\n",
        "        print(\"Epoch:\", epoch+1)\n",
        "\n",
        "        model.train(True)\n",
        "\n",
        "        running_losses = []\n",
        "        running_accuracies = []\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            X_batch, y_batch = batch\n",
        "\n",
        "            logits = model(X_batch.to(device))\n",
        "\n",
        "            loss = loss_fn(logits, y_batch.to(device))\n",
        "            running_losses.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            model_answers = torch.argmax(logits, dim=1)\n",
        "            train_accuracy = torch.sum(y_batch == model_answers.cpu()) / len(y_batch)\n",
        "            running_accuracies.append(train_accuracy)\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print(\"Средние train лосс и accuracy на последних 50 итерациях:\",\n",
        "                      np.mean(running_losses), np.mean(running_accuracies), end='\\n')\n",
        "\n",
        "        model.train(False)\n",
        "\n",
        "        val_accuracy, val_loss = evaluate(model, val_loader, loss_fn=loss_fn)\n",
        "        print(\"Эпоха {}/{}: val лосс и accuracy:\".format(epoch+1, n_epoch,),\n",
        "                      val_loss, val_accuracy, end='\\n')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KYqzqj02jZly"
      },
      "outputs": [],
      "source": [
        "model = ConvNet()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMgy5EGsnEZt",
        "outputId": "d5cc7d52-1017-483c-8e6d-fb4ccf0fee12"
      },
      "outputs": [],
      "source": [
        "model = train(model, loss_fn, optimizer, n_epoch=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fdsfmmGUntS",
        "outputId": "e0c57bd9-f725-480f-e5ad-5a2fe27bf057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5993\n"
          ]
        }
      ],
      "source": [
        "test_accuracy, _ = evaluate(model, test_loader, loss_fn)\n",
        "print('Accuracy:', test_accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
